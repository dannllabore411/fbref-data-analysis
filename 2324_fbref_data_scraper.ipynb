{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General idea\n",
    "This notebook shows the process from raw FBRef data to an exported csv file for future use:\n",
    "* data scraping - using pandas' read_html, requests, and StringIO methods in a reusable function to customize league, season, and stat types\n",
    "* data cleaning - cleaning up column names, dropping duplicates, and making data more readable\n",
    "* feature engineering - converting data to per-90 (per game equivalent) basis, and creating new metrics derived from existing variables for better analysis\n",
    "* data exporting - to a csv file for use in other projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up basic libraries\n",
    "\n",
    "* <b>numpy, pandas</b> - for data processing\n",
    "* <b>requests, StringIO</b> - for data scraping\n",
    "* <b>time</b> - delay/sleep between requests\n",
    "* <b>timeit</b> - measuring speed/performance\n",
    "* <b>warnings</b> - suppressing warnings (mainly performance warnings due to dataframe sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import timeit\n",
    "import warnings\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a dictionary of league IDs\n",
    "* <b>leagues_url_dict</b> - mapping league inputs to IDs for url requests <br>\n",
    "* <b>leagues_name_dict</b> - mapping league inputs to readable names for display in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues_url_dict = {\n",
    "    \"Big5\": \"Big-5-European-Leagues\",\n",
    "    \"Championship\": \"10\",\n",
    "    \"Serie-B\": \"18\",\n",
    "    \"Major-League-Soccer\": \"22\",\n",
    "    \"Eredivisie\": \"23\",\n",
    "    \"Primeira-Liga\": \"32\",\n",
    "    \"Belgian-Pro-League\": \"37\"\n",
    "}\n",
    "\n",
    "leagues_name_dict = {\n",
    "    \"eng Premier League\": \"ENG Premier League\",\n",
    "    \"de Bundesliga\": \"GER Bundesliga\",\n",
    "    \"fr Ligue 1\": \"FRA Ligue 1\",\n",
    "    \"es La Liga\": \"ESP La Liga\",\n",
    "    \"it Serie A\": \"ITA Serie A\",\n",
    "    \"Eredivisie\": \"NED Eredivisie\",\n",
    "    \"Primeira-Liga\": \"POR Primeira Liga\",\n",
    "    \"Belgian-Pro-League\": \"BEL Pro League\",\n",
    "    \"Championship\": \"ENG2 Championship\",\n",
    "    \"Serie-B\": \"ITA2 Serie B\",\n",
    "    \"Major-League-Soccer\": \"USA Major League Soccer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting leagues and types of stats to scrape\n",
    "Every combination of items in <b>leagues</b> and <b>stats_reqd</b> will be scraped:<br>\n",
    "* <b>leagues</b> contains the list of leagues to scrape\n",
    "* <b>stats_reqd</b> contains the list of type of stats to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues = [\"Big5\", \"Eredivisie\", \"Primeira-Liga\", \"Belgian-Pro-League\"]\n",
    "stats_reqd = [\"stats\", \"shooting\", \"passing\", \"passing_types\", \"gca\", \"defense\", \"possession\", \"misc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a reusable function to scrape data from FBREF\n",
    "Function <b>clean</b> uses pandas' <b>read_html</b> function and takes in three inputs:<br>\n",
    "* league - league to scrape (e.g. from list <b>leagues</b> in previous block)\n",
    "* year - season (e.g. \"2023-2024\" used in the code)\n",
    "* type - type of stat (e.g. from list <b>stats_reqd</b> in previous block)\n",
    "\n",
    "What <b>clean</b> does:<br>\n",
    "* Part A: Check variables <b>league</b>, <b>year</b> and <b>type</b> to generate url<br>\n",
    "* Part B: Uses pandas' <b>read_html</b> with <b>requests</b> and <b>StringIO</b> to scrape the needed dataframe<br>\n",
    "* Part C: Cleans up dataframe, specifically the column names with multi-indexes and extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(league, year, reqd):\n",
    "    # PART A\n",
    "    # Check which league(s) to get needed league IDs for URL\n",
    "    if league == \"Big5\":\n",
    "        league2 = \"Big5\"\n",
    "        league = leagues_url_dict[league2]\n",
    "    else:\n",
    "        league2 = leagues_url_dict[league]\n",
    "    # Check type of table to get table_id, specific URL\n",
    "    if reqd == \"table\":\n",
    "        url = \"https://fbref.com/en/comps/\" + league2 + \"/\" + year + \"/\" + year + \"-\" + league + \"-Stats\"\n",
    "        if league == \"Big-5-European-Leagues\":\n",
    "            table_id = \"big5_table\"\n",
    "        else:\n",
    "            table_id = \"results\" + year + league2 + \"1_overall\"\n",
    "    else:\n",
    "        if reqd == \"stats\":\n",
    "            table_id = \"stats_standard\"            \n",
    "        elif reqd == \"playingtime\":\n",
    "            table_id = \"stats_playing_time\"\n",
    "        else:\n",
    "            table_id = \"stats_\" + reqd\n",
    "        url = \"https://fbref.com/en/comps/\" + league2 + \"/\" + year + \"/\" + reqd + \"/players/\" + year + \"-\" + league + \"-Stats\"\n",
    "    # PART B\n",
    "    # pd.read_html to get table using specific URL\n",
    "    df = pd.read_html(StringIO(str(requests.get(url).text.replace('<!--','').replace('-->',''))), attrs={'id':table_id})[0]\n",
    "    df.columns = [' '.join(col).strip() for col in df.columns]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # PART C\n",
    "    # Setting up column names\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        if 'level_0' in col:\n",
    "            new_col = col.split()[-1]  # takes the last name\n",
    "        else:\n",
    "            new_col = col\n",
    "        new_columns.append(new_col)\n",
    "    df.columns = new_columns\n",
    "    df = df.fillna(0)\n",
    "    if reqd == \"table\":\n",
    "        df.columns = df.columns.str.replace(' ', '')\n",
    "    else:\n",
    "        df = df[df['Player'] != 'Player']\n",
    "        df = df.drop(['Rk'], axis=1)\n",
    "        if league2 != \"Big5\":\n",
    "            df[\"Comp\"] = league\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data\n",
    "Iterating through each combination of leagues in <b>leagues</b> and stats type in <b>stats_reqd</b>, appending each dataframe to create one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Big5 stats in 11.02 seconds\n",
      "Imported Eredivisie stats in 6.99 seconds\n",
      "Imported Primeira-Liga stats in 6.91 seconds\n",
      "Imported Belgian-Pro-League stats in 6.89 seconds\n",
      "Imported Big5 shooting in 9.61 seconds\n",
      "Imported Eredivisie shooting in 6.91 seconds\n",
      "Imported Primeira-Liga shooting in 8.83 seconds\n",
      "Imported Belgian-Pro-League shooting in 6.72 seconds\n",
      "Imported Big5 passing in 11.21 seconds\n",
      "Imported Eredivisie passing in 6.95 seconds\n",
      "Imported Primeira-Liga passing in 8.40 seconds\n",
      "Imported Belgian-Pro-League passing in 7.14 seconds\n",
      "Imported Big5 passing_types in 8.99 seconds\n",
      "Imported Eredivisie passing_types in 6.92 seconds\n",
      "Imported Primeira-Liga passing_types in 6.90 seconds\n",
      "Imported Belgian-Pro-League passing_types in 6.76 seconds\n",
      "Imported Big5 gca in 9.54 seconds\n",
      "Imported Eredivisie gca in 6.78 seconds\n",
      "Imported Primeira-Liga gca in 7.22 seconds\n",
      "Imported Belgian-Pro-League gca in 6.85 seconds\n",
      "Imported Big5 defense in 9.61 seconds\n",
      "Imported Eredivisie defense in 7.12 seconds\n",
      "Imported Primeira-Liga defense in 6.92 seconds\n",
      "Imported Belgian-Pro-League defense in 6.85 seconds\n",
      "Imported Big5 possession in 10.42 seconds\n",
      "Imported Eredivisie possession in 7.26 seconds\n",
      "Imported Primeira-Liga possession in 7.02 seconds\n",
      "Imported Belgian-Pro-League possession in 7.13 seconds\n",
      "Imported Big5 misc in 10.99 seconds\n",
      "Imported Eredivisie misc in 6.73 seconds\n",
      "Imported Primeira-Liga misc in 8.70 seconds\n",
      "Imported Belgian-Pro-League misc in 6.74 seconds\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for x in stats_reqd:\n",
    "    df = pd.DataFrame()\n",
    "    for y in leagues:\n",
    "        import_start = timeit.default_timer()\n",
    "        df = pd.concat([df, clean(y, \"2023-2024\", x)], axis=0, sort=False).reset_index(drop=True)\n",
    "        time.sleep(6)\n",
    "        import_stop = timeit.default_timer()\n",
    "        print(\"Imported %s %s in %.2f seconds\" % (y, x, import_stop - import_start))\n",
    "    frames.append(df)\n",
    "dataset = pd.concat(frames, axis=1, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset\n",
    "* Dropping all duplicated columns\n",
    "* Filling all NaN values with 0\n",
    "* Cleaning the <b>Nation</b> column to three-letter codes\n",
    "* Cleaning the <b>Comp</b> column to readable league names, reordering to left side of dataframe\n",
    "* Dropping irrelevant columns: <b>90s</b> redundant with Minutes Played, <b>Matches</b> contains text/link only\n",
    "* Converting all columns after player identifiers (categorical) to <b>numeric</b>\n",
    "* Converting all non-percentage, non-\"per-90\" basis stats to <b>per-90</b> basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_26304\\812199887.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset = dataset.fillna(0)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.loc[:,~dataset.columns.duplicated()].copy()\n",
    "dataset['Nation'] = dataset['Nation'].str.split(' ').str.get(1)\n",
    "dataset[\"Comp\"] = dataset[\"Comp\"].map(leagues_name_dict)\n",
    "dataset.drop(dataset.filter(regex='90').columns, axis=1, inplace=True)\n",
    "dataset.drop(dataset.filter(regex='Matches').columns, axis=1, inplace=True)\n",
    "col = dataset.pop('Comp')\n",
    "dataset.insert(5, col.name, col)\n",
    "dataset.iloc[:,8:] = dataset.iloc[:,8:].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "for col in dataset.columns[11:]:\n",
    "    if ('90' in col) or ('%' in col):\n",
    "        pass\n",
    "    else:\n",
    "        dataset[col] = dataset[col]/(dataset['Playing Time Min']/90)\n",
    "dataset = dataset.fillna(0)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new variables\n",
    "* <b>Success rate metrics:</b> Tackles Tkl%, Foul Prev%\n",
    "* <b>Aggregated metrics:</b> Deep DAs and High DAs (Defensive Actions)\n",
    "* <b>%Touches:</b> proportion of touches by specific zone (Def Pen, Def 3rd, Mid 3rd, Att 3rd, Att Pen)\n",
    "* <b>%Pass Att:</b> proportion of attempted passes by pass length (Short, Medium, Long)\n",
    "* <b>xAG/SCA:</b> like xG/Shot, but for chance creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Tackles Tkl%\"] = np.where(dataset[\"Tackles Tkl\"]!=0, (100*dataset[\"Tackles TklW\"].astype(float)/dataset[\"Tackles Tkl\"].astype(float)), 0)\n",
    "dataset[\"Foul Prev%\"] = np.where(dataset[\"Tackles Tkl\"]!=0, (100*1-(dataset[\"Performance Fls\"].astype(float)/dataset[\"Tackles Tkl\"].astype(float))), 0)\n",
    "dataset[\"Touches %Def Pen\"] = np.where(dataset[\"Touches Touches\"]!=0, (100*dataset[\"Touches Def Pen\"].astype(float)/dataset[\"Touches Touches\"].astype(float)), 0)\n",
    "dataset[\"Touches %Def 3rd\"] = np.where(dataset[\"Touches Touches\"]!=0, (100*dataset[\"Touches Def 3rd\"].astype(float)/dataset[\"Touches Touches\"].astype(float)), 0)\n",
    "dataset[\"Touches %Mid 3rd\"] = np.where(dataset[\"Touches Touches\"]!=0, (100*dataset[\"Touches Mid 3rd\"].astype(float)/dataset[\"Touches Touches\"].astype(float)), 0)\n",
    "dataset[\"Touches %Att 3rd\"] = np.where(dataset[\"Touches Touches\"]!=0, (100*dataset[\"Touches Att 3rd\"].astype(float)/dataset[\"Touches Touches\"].astype(float)), 0)\n",
    "dataset[\"Touches %Att Pen\"] = np.where(dataset[\"Touches Touches\"]!=0, (100*dataset[\"Touches Att Pen\"].astype(float)/dataset[\"Touches Touches\"].astype(float)), 0)\n",
    "dataset[\"%Short Att\"] = np.where(dataset[\"Total Att\"]!=0, (100*dataset[\"Short Att\"].astype(float)/dataset[\"Total Att\"].astype(float)), 0)\n",
    "dataset[\"%Medium Att\"] = np.where(dataset[\"Total Att\"]!=0, (100*dataset[\"Medium Att\"].astype(float)/dataset[\"Total Att\"].astype(float)), 0)\n",
    "dataset[\"%Long Att\"] = np.where(dataset[\"Total Att\"]!=0, (100*dataset[\"Long Att\"].astype(float)/dataset[\"Total Att\"].astype(float)), 0)\n",
    "dataset[\"xAG/SCA\"] = np.where(dataset[\"SCA SCA\"]!=0, (100*dataset[\"xAG\"].astype(float)/dataset[\"SCA SCA\"].astype(float)), 0)\n",
    "dataset[\"Deep DAs\"] = dataset[\"Blocks Sh\"] + dataset[\"Clr\"] + dataset[\"Tackles Def 3rd\"]\n",
    "dataset[\"High DAs\"] = dataset[\"Tackles Mid 3rd\"] + dataset[\"Tackles Att 3rd\"] + dataset[\"Int\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting dataset\n",
    "Exporting the dataset to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"2324_top_8_raw.csv\", encoding=\"utf-8\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
